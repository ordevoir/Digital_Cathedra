{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ordevoir/Data_Analysis/blob/main/pandas_load_and_review_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7q6cLObt_ij"
   },
   "source": [
    "# Данные\n",
    "\n",
    "**Данные** (*Data*) – представление информации в формализованном виде, пригодном для хранения, передачи или обработки.\n",
    "\n",
    "Данные представляют собой наборы фактов, чисел, текстов или других видов информации, которые собираются, хранятся и обрабатываются для получения знаний, принятия решений или выявления закономерностей. В контексте анализа данных данные служат основой для проведения различных аналитических процессов, таких как статистический анализ, машинное обучение, визуализация данных и другие методы, направленные на извлечение ценной информации.\n",
    "\n",
    "**Анализ данных** (*Data Analysis*) – это процесс, который включает в себя сбор, обработку, изучение и интерпретацию данных с целью извлечения полезной информации и принятия решений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Структурированные данные** (*Structured Data*) обладают четкой организацией и форматированием, что облегчает их обработку и анализ. Они обычно хранятся в табличных форматах, таких как базы данных или электронные таблицы (файлы Excel, csv и т.д.). \n",
    "\n",
    ">не путать со структурами данных: одни и те же структурированные данные могут храниться посредством разных структур данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Неструктурированные данные** (*Unstructured Data*) не имеют предопределенной модели или структуры, что затрудняет их обработку с использованием традиционных методов анализа данных. Они часто представляют собой сложные формы информации, которые требуют специальных методов обработки, таких как обработка естественного языка или компьютерное зрение. Примерами могут служить изображения, видео или аудиозаписи, текстовые документы. Сами файлы, конечно имеют определенную структуру, но содержащаясия в них информация не структурированна."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Полуструктурированные данные** (*Semi-structured data*) содержат элементы структурированности, но не соответствуют строгим схемам, характерным для структурированных данных. Они обладают метаданными, которые помогают организовать и классифицировать информацию. Это к примеру такие файлы как XML, JSON, HTML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Временные данные** (*Time Series Data*) – последовательности данных, собранные или записанные в последовательные моменты времени. Они используются для анализа трендов, сезонных колебаний и прогнозирования будущих значений на основе исторических данных. Примеры: курсы аккций, динамика экономических показателей, погодные данные, динамика медицинсикх показателей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HxPedOm6t_ik"
   },
   "source": [
    "# Элементы структурированных данных\n",
    "\n",
    "В таблицах структурированных данных каждая колонка представляет собой определенный **тип данных** (*data type*), который можно классифицировать по нескольким признакам. \n",
    "\n",
    "Можно выделить два основных типа данных: числовые и категориальные. \n",
    "\n",
    "**Числовые** (*numerical*) или **количественные** (*quantitative*) данные представляются в виде чисел и подразделяются на два типа: **непрерывные** (*continuous*) или **дискретные** (*discrete*) числовые данные. С числовыми данными можно производить арифметические манипуляции, между значениями легко определить способ измерения расстояния. Имеет смысл вычислять среднее от значений и т.д.\n",
    "\n",
    "**Категориальные** (*categorical*) или **качественные** (*qualitative*) данные как правило принимают значения из ограниченного и фиксированного множества. Различают номинальные и порядковые категориальные данные.\n",
    "\n",
    "**Номинальные** (*nominal*) данные группируются во взаимоисключающие описательные категории, между которыми нет отношения порядка. Примерами могут быть такие признаки как цвет волос, группа крови, вид спорта или марка автомобиля. Несмотря на то, что группы крови могут быть представлены в виде чисел, эти числа не имеют арифметического значения, и нет смысла сравнивать их по величине.\n",
    "\n",
    "**Порядковые** (*ordinal*) отличаются от номинальных тем, что в категориях есть естественный порядок, например, уровень образования, уровень дохода, тяжесть состояния больного. Принципиальное отличие порядковых данных от числовых в том, что для них не определена шкала, в соответствии с которой можно было бы говорить о расстоянии, между значениями. Поэтому арифметические операции и поиск среднего значения не имеет большого смысла."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные, представленные в виде целых чисел, могут быть отнесены к категориальному типу, если значения представляют собой просто идентификаторы, и не несут в себе количественной информации, пригодной для математических операций. Примером может служить номер дома в адресе, номер телефона и тд."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uh5Enw0Ft_il"
   },
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruGXOFC7t_il"
   },
   "source": [
    "[Pandas](\"https://pandas.pydata.org/) – это библиотека, которая предоставляет инструменты для анализа структурированных данных. Основными структурами в Pandas являются [`DataFrame`](https://pandas.pydata.org/docs/reference/frame.html) и [`Series`](https://pandas.pydata.org/docs/reference/api/pandas.Series.html).\n",
    "- `DataFrame` – это двумерная таблица, которая содержит данные различных типов.  \n",
    "- `Series` представляет собой единственную колонку с данными.\n",
    "\n",
    "Эти структуры данных также содержат названия для строк и колонок.\n",
    "\n",
    "Pandas также предоставляет инструменты для чтения и записи данных из различных источников, таких как CSV, Excel, базы данных, веб-API и т.д.\n",
    "\n",
    "Установить библиотеку Pandas в Python можно выполнив в терминале\n",
    "\n",
    "```bash\n",
    "pip install pandas\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9po1Q4F8t_il"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLZ4an1Ct_im"
   },
   "source": [
    "---\n",
    "\n",
    "# Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "go0gAyxvt_im"
   },
   "source": [
    "Загрузим данные из файла data.csv формата CSV (*comma-separated values*), расположенного на локальном диске. Фактически это текстовый файл, в котором задана таблица, строки которой разделены переносом на новую строку, а колонки разделены запятыми. Откройте этот файл в текстовом редакторе и просмотрите его. Убедитесь, что это такие же данные, какие были сгенерированы в файле matplotlib_examples.ipynb. Вы можете также открыть файл data.csv в Microsoft Excel.\n",
    "\n",
    "Для того, чтобы загрузить данные из файла формата CSV используется функция `read_csv()` в которую передается в качестве аргумента путь к файлу. Функция возвращает объект класса `DataFrame`:\n",
    "\n",
    ">```python\n",
    ">pd.read_csv('directory/file_name.csv')\n",
    ">```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ETuiI-JosZa"
   },
   "source": [
    "## Загрузка данных из GoogleDrive\n",
    "\n",
    "Для того, чтобы использовать GoogleDrive в качестве локального диска, необходимо монтировать диск. Для этого используется функция `mount()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l5MxsFfEvNd8"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYvTB6DepbQJ"
   },
   "source": [
    "Теперь функция `read_csv()` может считать данные из файла, расположенного в GoogleDrive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yZU2Qx-6wLhe"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('drive/MyDrive/Colab Notebooks/data.csv')\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8isAiTs_t_in"
   },
   "outputs": [],
   "source": [
    "# посмотрим на загруженные данные\n",
    "data.head()     # просмотр первых пяти строк\n",
    "# data          # просмотр данных целиком"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bSnwsDKst_in"
   },
   "source": [
    "## Загрузка данных из репозитория\n",
    "\n",
    "В общем случае можно загружать данных из любых удаленных источников, предоставляющих прямой доступ к файлу csv. В качестве примера загрузим данные из GitHub (файл расположен в репозитории [Data_Analysis](https://github.com/ordevoir/Data_Analysis))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nO7etbz1t_in"
   },
   "outputs": [],
   "source": [
    "housing = pd.read_csv('https://raw.githubusercontent.com/ordevoir/Data_Analysis/main/housing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-BTXPz4YqfF5"
   },
   "source": [
    "> Существуют множество других форматов данных и способов загрузки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '.\\\\housing.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m housing \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mhousing.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\werna\\miniconda3\\envs\\ml\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\werna\\miniconda3\\envs\\ml\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\werna\\miniconda3\\envs\\ml\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\werna\\miniconda3\\envs\\ml\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\werna\\miniconda3\\envs\\ml\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.\\\\housing.csv'"
     ]
    }
   ],
   "source": [
    "housing = pd.read_csv(\".\\housing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\werna\\Documents\\GitHub\\Digital_Cathedra\\Data Analysis\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "work_dir = os.path.abspath(\"\")\n",
    "print(work_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JX_8Tk0gt_in"
   },
   "source": [
    "# [`DataFrame`](https://pandas.pydata.org/docs/reference/frame.html)\n",
    "\n",
    "В таблице `DataFrame` в строках записаны данные об **оразцах** (*samples*), а колонкам таблицы соответствуют признаки (*features*). В терминах баз данных можно сказать, что в строках расположены **записи** (*records*) об экземплярах, а колонки соответствуют **полям** (*fields*), также используется понятие **атрибут** (*atribute*).\n",
    "\n",
    "Колонки таблицы умеют названия, соовтетствующие названиям признаков. Традиционные таблицы базы данных содержат колоноку (или несколько колонок) для индексации. Это значительно повышает эффективность некоторых запросов\n",
    "к базе данных. По умолчанию для объекта `DataFrame` создается автоматический целочисленный индекс, который основывается на порядке следования строк таблицы. В pandas также существует возможность задавать многоуровневые/иерархические индексы с целью повышения эффективности некоторых операций."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7M5GiiH8tF0o"
   },
   "source": [
    "### `head()`, `info()`, `describe()`, `hist()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JnKLt-FZt_io"
   },
   "outputs": [],
   "source": [
    "housing.head()  # вывод первых пяти образцов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5C-XAfF-t_io"
   },
   "source": [
    "При помощи метода `info()` можно увидеть, сколько всего образцов, сколько признаков, какое количество непустых значений параметров, какие у них типы данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YnhBlLzFt_io"
   },
   "outputs": [],
   "source": [
    "housing.info()  # вывод информации о признаках"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QGgCiVKJt_io"
   },
   "source": [
    "Статистическое описание признаков можно посмотреть при помощи метода `describe()`.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aGl1neNKt_io"
   },
   "outputs": [],
   "source": [
    "housing.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tOE9hZb0t_ip"
   },
   "source": [
    "Если вызвать метод `hist()` у объекта класса `DataFrame`, то будут визуализировано распределение всех числовых признаков. В параметре `bins` можно задать число ячеек, которые будут использовны при построении гистограммы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9dfVhCpwt_ip"
   },
   "outputs": [],
   "source": [
    "housing.hist(bins=15, figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UtsF6DZht_ip"
   },
   "source": [
    "# [`Series`](https://pandas.pydata.org/docs/reference/series.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXyJ-GJNt_iq"
   },
   "source": [
    "Если извлечь из объекта `DataFrame` данные одного из признаков (колонку), получим объект класса `Series`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "adHg_Takt_iq"
   },
   "outputs": [],
   "source": [
    "s = housing['latitude']\n",
    "s.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SO8k_npqt_io"
   },
   "source": [
    "При помощи метода `value_counts()` можно посмотреть распределение значений для отдельного признака: список принимаемых значений, и количество образцов с этим значением. Это полезно, когда принимаемых значений не так много. Обычно это касается категориальных признаков, таких как `ocean_proximity` в данных `housing`. Заметим, что доступ к колонке признака производится по ключу, подобно тому, как это делается в словарях (`dict`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ptWjRo4Ut_io"
   },
   "outputs": [],
   "source": [
    "housing['ocean_proximity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Px7jaugvt_ip"
   },
   "source": [
    "Метод `hist()` позволяет визуализировать распределение значений признака. Сравните значения, полученные в предыдущей ячейке с кодом, со значениями на диаграмме:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RlLsbbEXt_ip"
   },
   "outputs": [],
   "source": [
    "housing['ocean_proximity'].hist(figsize=(5, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQGkegrXt_ip"
   },
   "source": [
    "Особенно полезен метод `hist()` для числовых признаков, когда принимаемых значений очень много, и метод `value_counts()` уже не выводит удобные для восприятия данные. Попробуйте вместо `hist()` вызвать метод `value_counts()` и посмотрите результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4pRfUP58t_ip"
   },
   "outputs": [],
   "source": [
    "housing['median_house_value'].hist(bins=36, figsize=(5,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4IF0lq1U4Pn8"
   },
   "source": [
    "# Визуализация данных\n",
    "\n",
    "Визуализация данных может помочь нам увидеть некоторые закономерности в данных, корреляции между признаками, которые впоследствии можно будет использовать для анализа данных.\n",
    "\n",
    "Так как в наших данных содержится информация о географическом расположении образцов, имеет смысл визуализировать расположение точек (`longitude`, `latitude`). Визуализацию можно произвести при помощи метода `plot()`. Так как мы хотим визуализировать значения в виде точек, зададим параметр `kind=\"scatter\"`. Для более приглядной визуализации сделаем точки полупрозрачными, задав параметр `alpha=0.1`, что позволит нам разглядеть области наиболее плотного расположения точек."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "brmUB-7s57EL"
   },
   "outputs": [],
   "source": [
    "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HyJOS0tD6Aar"
   },
   "source": [
    "На этой же диаграмме мы можем отобразить информацию и о других признаках, используя различные цвета и размеры точек. Параметр `s` определяет размер точек, а параметр `c` – цвет точки. Размеры точек будут соответствовать признаку `population`, а цвета точек – признаку `median_house_value`. Карта цветов задается в параметре `cmap`. Различные цветовые карты представлены [здесь](https://matplotlib.org/stable/users/explain/colors/colormaps.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4yoHNiZQ4VSp"
   },
   "outputs": [],
   "source": [
    "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\",\n",
    "    alpha=0.1,                      # значение непрозрачности для точки\n",
    "    s=housing[\"population\"]/100,    # размер точки\n",
    "    c=\"median_house_value\",         # цвет точки\n",
    "    cmap=plt.get_cmap(\"jet\"),       # цветовая карта\n",
    "    colorbar=True,                  # отображать шкалу цветов\n",
    "    label=\"papulation\",\n",
    "    figsize=(10,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B79bYOWV-9G-"
   },
   "source": [
    "# Поиск корреляций\n",
    "\n",
    "Если данные не слишком большие, можно легко вычислить [коэффициент корреляции Пирсона](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient) для каждой пары признаков, используя метод [`corr()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html) объекта класса `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3poIsU7tANM0"
   },
   "outputs": [],
   "source": [
    "corr_matrix = housing.corr()\n",
    "type(corr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pDDepj8aAwY2"
   },
   "source": [
    "Выведем коэффициенты корреляции с признаком `median_house_value`. Эти значения находятся в колонке `median_house_value` объекта `corr_matrix`. Для того, чтобы вывод значений был упорядоченным, воспользуемся методом `sort_values()` и зададим значение параметра `ascending=False`, чтобы список шел по убыванию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B-IdwlelAl1S"
   },
   "outputs": [],
   "source": [
    "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k2NH0Y5aDR1s"
   },
   "source": [
    "Видим, что имеется выраженная корреляция с признаком `median_income`. Также видим, что имеется некоторая отрицательная корреляция с широтой (`latitude`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmWl-6RoDJLK"
   },
   "source": [
    "Корреляции можно искать также и визуально. Попробуем визуализировать матрицы рассеяния (*scatter matrix*) между парами признаков. Нас будут интересовать признаки `\"median_house_value\", \"median_income\", \"total_rooms\", \"housing_median_age\"`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8kZJLbsdEeeR"
   },
   "outputs": [],
   "source": [
    "features = [\"median_house_value\",\n",
    "              \"median_income\",\n",
    "              \"total_rooms\",\n",
    "              \"housing_median_age\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8MT6Ahh3Eo1o"
   },
   "source": [
    "Для визуализации матриц рассеяния воспользуемся функцией `scatter_matrix()` из модуля `plotting` библиотеки `pandas`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LAdb_vtJEhh7"
   },
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "scatter_matrix(housing[features], figsize=(12, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajVLciEZFh87"
   },
   "source": [
    "На диаграммах также видно, что наиболее выраженная корреляция признака `median_house_value` наблюдается с признаком `median_income`. Выведем отдельно эту диаграмму отдельно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y_61TF94Fzty"
   },
   "outputs": [],
   "source": [
    "housing.plot(kind=\"scatter\",\n",
    "             x=\"median_income\",\n",
    "             y=\"median_house_value\",\n",
    "             alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A-a0vfNzHDbo"
   },
   "source": [
    "> В данной визуализации можно также заметить выраженную горизонтальную линию на уровне 500 000 долларов. Можно предположить, что это некоторое ценовое ограничение, которое вносит искажение в данные. Можно попробовать удалить соответствующие районы, чтобы ваши алгоритмы не обучались воспроизведению этих причуд данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yBi6vk5GImAR"
   },
   "source": [
    "# Корреляция с комбинацией признаков\n",
    "\n",
    "В данном наборе данных целевым признаком является `median_house_value`. Возможно, что с целевым признаком больше коррелируют не сами признаки образцов а отношения между признаками Можно создать новые признаки, как комбинации имеющихся, и посмотреть, не будут ли они больше коррелировать с целевым признаком."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HgHLBoKsF1WK"
   },
   "outputs": [],
   "source": [
    "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
    "housing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"]/housing[\"total_rooms\"]\n",
    "housing[\"population_per_household\"]=housing[\"population\"]/housing[\"households\"]\n",
    "\n",
    "corr_matrix = housing.corr()\n",
    "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QjqepwvlJ9f6"
   },
   "source": [
    "В самом деле `rooms_per_household` больше коррелирует с целевым  признаком `median_house_value`, чем признаки `total_rooms` и `households` по-отдельности. Также и с `bedrooms_per_room` наблюдается хорошая отрицательная корреляция, так что эти новые признаки могли бы быть полезны."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
